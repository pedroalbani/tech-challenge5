# üöÄ Guia para Rodar o Projeto com Docker

Este projeto utiliza **Docker Compose** para configurar e rodar os servi√ßos necess√°rios, incluindo **MongoDB**, **Mongo Express** e **MLflow**.

---

## üìå **Pr√©-requisitos**

Antes de come√ßar, certifique-se de ter instalado:

- [Docker](https://docs.docker.com/get-docker/)
- [Docker Compose](https://docs.docker.com/compose/install/)

---

## üîß **Configura√ß√£o Inicial**

### 1Ô∏è‚É£ Criar o arquivo de vari√°veis de ambiente `.env`

Crie um arquivo chamado `.env` na raiz do projeto e adicione:

```
MONGO_USERNAME=root
MONGO_PASSWORD=example
MONGO_DATABASE=admin
MONGO_PORT=27017

MLFLOW_PORT=8080
```

---

## üöÄ **Rodando o Projeto**

### 2Ô∏è‚É£ Subindo os containers com Docker Compose

Para iniciar todos os servi√ßos, execute:

```
docker-compose up -d
```

üìå Isso iniciar√° os servi√ßos em segundo plano (`-d` = _detached mode_).

### 3Ô∏è‚É£ **Verificando os logs**

Se precisar visualizar os logs de um servi√ßo espec√≠fico, use:

```
docker logs -f <nome_do_servi√ßo>
```

Exemplos:

```
docker logs -f mongo_db_tech_5
docker logs -f mlflow_server
```

---

## üéØ **Acessando os Servi√ßos**

### üîπ **Mongo Express** (Interface gr√°fica do MongoDB)

Acesse no navegador:

```
http://localhost:8081
```

Use as credenciais do `.env` (`MONGO_USERNAME` e `MONGO_PASSWORD`).

### üîπ **MLflow** (Gerenciamento de Experimentos)

Acesse no navegador:

```
http://localhost:8080
```

---

## üõë **Parando os Containers**

Para parar todos os servi√ßos rodando:

```
docker-compose down
```

Se quiser remover volumes e dados armazenados:

```
docker-compose down -v
```

---

## üêû **Rodando em Modo Debug**

Caso queira rodar apenas o banco de dados e executar a aplica√ß√£o manualmente no modo debug:

```
docker-compose up -d mongo
```

Agora, voc√™ pode rodar seu c√≥digo localmente sem precisar subir os outros servi√ßos.

---

## üõ† **Dicas e Problemas Comuns**

### üîπ **Erro de porta em uso**

Se receber um erro de que a porta est√° em uso:

```
ERROR: Bind for 0.0.0.0:27017 failed: port is already allocated
```

Tente parar os servi√ßos que est√£o rodando na porta 27017:

```
docker ps  # Lista os containers em execu√ß√£o
docker stop <id_do_container>
docker rm <id_do_container>
```

---

Agora seu ambiente est√° pronto para rodar com Docker! üöÄ

# Conjunto de Treino - Datathon Fase 5

## Introdu√ß√£o

O conjunto de treino do Datathon da Fase 5 foi projetado para fornecer dados estruturados que permitem a constru√ß√£o de um sistema de recomenda√ß√£o eficiente para conte√∫dos da Globo. Ele cont√©m informa√ß√µes sobre usu√°rios, seu hist√≥rico de intera√ß√µes e os conte√∫dos acessados.

## Estrutura do Conjunto de Treino

Os dados de treino foram divididos em m√∫ltiplas partes (arquivos `treino_parte_X.csv`, onde X varia de 1 a 6) e armazenados em diferentes pastas. Eles cont√™m as seguintes colunas:

### **Informa√ß√µes dos Usu√°rios**

- **`userId`**: Identifica√ß√£o √∫nica do usu√°rio.
- **`userType`**: Indica se o usu√°rio est√° logado ou √© an√¥nimo.
- **`HistorySize`**: N√∫mero total de not√≠cias lidas pelo usu√°rio.
- **`history`**: Lista de not√≠cias visitadas pelo usu√°rio.
- **`TimestampHistory`**: Momento em que o usu√°rio acessou a p√°gina.
- **`timeOnPageHistory`**: Tempo (em milissegundos) que o usu√°rio permaneceu na p√°gina.
- **`numberOfClicksHistory`**: N√∫mero total de cliques do usu√°rio na mat√©ria.
- **`scrollPercentageHistory`**: Porcentagem do conte√∫do visualizado pelo usu√°rio.
- **`pageVisitsCountHistory`**: Quantidade de vezes que o usu√°rio acessou a mat√©ria.

### **Informa√ß√µes dos Itens (Mat√©rias)**

Al√©m dos arquivos de hist√≥rico de usu√°rios, h√° uma subpasta chamada `itens` contendo detalhes sobre as mat√©rias acessadas:

- **`Page`**: ID √∫nico da mat√©ria (mesmo ID da coluna `history`).
- **`Url`**: URL da mat√©ria.
- **`Issued`**: Data em que a mat√©ria foi publicada.
- **`Modified`**: √öltima data de modifica√ß√£o da mat√©ria.
- **`Title`**: T√≠tulo da mat√©ria.
- **`Body`**: Conte√∫do textual da mat√©ria.
- **`Caption`**: Subt√≠tulo da mat√©ria.

## Considera√ß√µes Importantes

- Os dados foram coletados at√© um determinado per√≠odo (`T`), garantindo que refletem padr√µes reais de consumo.
- O conjunto de treino permite modelar padr√µes de leitura e prever conte√∫dos que os usu√°rios provavelmente acessar√£o no futuro.
- O problema do _cold-start_ deve ser tratado, pois novos usu√°rios ou conte√∫dos n√£o possuem hist√≥rico suficiente para alimentar o modelo.

## Pr√≥ximos Passos

O objetivo do Datathon √© desenvolver um modelo de recomenda√ß√£o capaz de prever as pr√≥ximas not√≠cias que um usu√°rio ir√° consumir, com base nos dados dispon√≠veis. O modelo precisa considerar a relev√¢ncia temporal e estrat√©gias de mitiga√ß√£o para o problema de _cold-start_.

---

Para acessar a base de dados e o dicion√°rio de dados, utilize o link oficial:
[Download da base de dados](https://drive.google.com/file/d/13rvnyK5PJADJQgYe-VbdXb7PpLPj7lPr/view)

Sobre os arquivos dispon√≠veis no drive acima

## Arquivos de Dados:

- **`validacao.csv`**: Dados de valida√ß√£o, incluindo hist√≥rico de intera√ß√µes dos usu√°rios.
- **`treino_parte1.csv`**: Dados de treino, contendo padr√µes de comportamento dos usu√°rios. ()
- **`itens-parte1.csv`**: Provavelmente cont√©m metadados dos itens recomend√°veis.
- **`test_top10_submission.csv`**: Submiss√£o de previs√µes para avalia√ß√£o do modelo.

## Scripts de Processamento:

- **`convert_kaggle.py`**: Processa os dados de valida√ß√£o, transformando o hist√≥rico de intera√ß√µes em um formato adequado para submiss√£o no Kaggle‚Äãconvert_kaggle.
- **`topk.py`**: Utiliza o hist√≥rico de intera√ß√µes dos usu√°rios para calcular os top 10 itens mais acessados por cada usu√°rio‚Äãtopk.

## Processamento de dados

Antes de treinar o modelo, na etapa de tratamento dos dados (feature store), iremos inputar um dado de categoria baseado no T√≠tulo e Subt√≠tulo das not√≠cias, em um cen√°rio real/ideal utilizariamos um outro Modelo de Machine Learning que atrav√©s da caria√ß√£o de tokens a partir do texto (ap√≥s a limpeza de "fillers"), seria capaz de categorizar os dados. Contudo, como esse n√£o √© o objetivo principal do projeto, sendo apenas um ponto que achamos interessante adicionar, iremos fazer de uma forma mais rudimentar.

Iremos predefinir grupos de palavras que esperamos encontrar, enquanto subdividimos as mat√©rias em 3 categorias: G1 (Not√≠cias em geral), GE (Not√≠cias esportivas) e EGO (entretenimento e afins), baseado nesses grupos pr√© definidos (salvos numa cole√ß√£o do mongo) e utilizando a gera√ß√£o de tokens dos textos previamente citados usando o scikit learn, criaremos mais um ponto importante a ser levado em considera√ß√£o durante a sugest√£o de pr√≥ximas mat√©rias.

O fluxo dos dados ser√° o seguinte:
<img src="./docs/img/data-flow.svg">

## Fluxo de vida do Modelo

O modelo treinado ser√° exportado para um .pickle usando Ml Flow, suas sugest√µes ser√£o salvas em uma collection do MongoDB, e junto com os dados futuros ser√£o utilizados para avalia√ß√£o do modelo em ambiente de produ√ß√£o (essa parte √© apenas como teorizamos que isso funcionar√° em um ambiente real, n√£o est√° no escopo do projeto atual), onde os clicks do usu√°rio e o tempo passado nas p√°ginas poderiam ser considerados a melhor forma de feedback.

<img src="./docs/img/life-cycle.svg">
